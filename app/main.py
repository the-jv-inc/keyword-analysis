"""
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚¤ãƒ‹ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«
"""

import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from itertools import combinations
import json
import os
from io import StringIO, BytesIO
from datetime import datetime, timedelta
import pickle
import base64

from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import japanize_matplotlib
import networkx as nx
import plotly.graph_objects as go

from janome.tokenizer import Tokenizer

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Keyword Mining", page_icon="K", layout="wide")

# Google Trendsé¢¨CSS
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;500&display=swap');

    .main .block-container {
        max-width: 1000px;
        padding: 2rem 1.5rem;
    }

    #MainMenu, footer, header { visibility: hidden; }

    html, body, [class*="css"] {
        font-family: 'Roboto', sans-serif;
    }

    h1 {
        font-size: 1.75rem !important;
        font-weight: 400 !important;
        color: #202124 !important;
        margin-bottom: 0.5rem !important;
    }

    h2 {
        font-size: 1.1rem !important;
        font-weight: 500 !important;
        color: #202124 !important;
        margin-bottom: 0.25rem !important;
    }

    .desc-text {
        font-size: 0.85rem;
        color: #5f6368;
        margin-bottom: 1rem;
        line-height: 1.4;
    }

    .stMetric {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e8eaed;
    }

    .stMetric label {
        font-size: 0.7rem !important;
        color: #5f6368 !important;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .stMetric [data-testid="stMetricValue"] {
        font-size: 1.5rem !important;
        font-weight: 500 !important;
        color: #202124 !important;
    }

    .stTabs [data-baseweb="tab-list"] {
        gap: 0;
        border-bottom: 1px solid #e8eaed;
    }

    .stTabs [data-baseweb="tab"] {
        font-size: 0.875rem;
        font-weight: 500;
        color: #5f6368;
        padding: 0.75rem 1.25rem;
        border-bottom: 3px solid transparent;
    }

    .stTabs [aria-selected="true"] {
        color: #1a73e8 !important;
        border-bottom: 3px solid #1a73e8 !important;
    }

    /* Googleé¢¨ãƒœã‚¿ãƒ³ */
    .stButton > button {
        font-family: 'Roboto', sans-serif !important;
        font-weight: 500 !important;
        font-size: 0.875rem !important;
        border-radius: 4px !important;
        padding: 8px 16px !important;
        border: 1px solid #dadce0 !important;
        background: white !important;
        color: #1a73e8 !important;
        transition: background 0.2s, box-shadow 0.2s !important;
        box-shadow: none !important;
    }

    .stButton > button:hover {
        background: #f8f9fa !important;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1) !important;
    }

    .stButton > button[kind="primary"],
    .stButton > button[data-testid="baseButton-primary"] {
        background: #1a73e8 !important;
        color: white !important;
        border: none !important;
    }

    .stButton > button[kind="primary"]:hover,
    .stButton > button[data-testid="baseButton-primary"]:hover {
        background: #1557b0 !important;
        box-shadow: 0 1px 3px rgba(0,0,0,0.2) !important;
    }

    /* ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */
    .stDownloadButton > button {
        font-family: 'Roboto', sans-serif !important;
        font-weight: 500 !important;
        font-size: 0.8rem !important;
        border-radius: 4px !important;
        padding: 10px 16px !important;
        border: 1px solid #dadce0 !important;
        background: white !important;
        color: #3c4043 !important;
        transition: all 0.2s !important;
    }

    .stDownloadButton > button:hover {
        background: #f1f3f4 !important;
        border-color: #c6c6c6 !important;
    }

    hr {
        border: none;
        border-top: 1px solid #e8eaed;
        margin: 2rem 0;
    }

    .stDataFrame {
        border: 1px solid #e8eaed;
        border-radius: 8px;
    }

    /* ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ */
    .upload-area {
        border: 2px dashed #dadce0;
        border-radius: 8px;
        padding: 2rem;
        text-align: center;
        background: #fafafa;
        margin-bottom: 1rem;
    }

    .upload-area:hover {
        border-color: #1a73e8;
        background: #f8f9fa;
    }

    /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼éè¡¨ç¤º */
    [data-testid="stFileUploader"] {
        padding: 0 !important;
    }

    [data-testid="stFileUploader"] section {
        padding: 0 !important;
    }

    [data-testid="stFileUploader"] section > input + div {
        display: none !important;
    }

    [data-testid="stFileUploader"] section > button {
        display: none !important;
    }
</style>
""", unsafe_allow_html=True)

# å®šæ•°
SCOPES = ['https://www.googleapis.com/auth/webmasters.readonly']
APP_DIR = os.path.dirname(os.path.abspath(__file__))
TOKEN_PATH = os.path.join(APP_DIR, 'token.pickle')
CREDENTIALS_PATH = os.path.join(APP_DIR, 'credentials.json')

# OAuthè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
GOOGLE_CLIENT_ID = os.environ.get('GOOGLE_CLIENT_ID', '')
GOOGLE_CLIENT_SECRET = os.environ.get('GOOGLE_CLIENT_SECRET', '')
REDIRECT_URI = os.environ.get('REDIRECT_URI', 'https://keyword-analysis-rrzzyfm8ktruqrca4k7nfv.streamlit.app')
COLORS = {
    'blue': '#1a73e8',
    'red': '#ea4335',
    'yellow': '#fbbc04',
    'green': '#34a853',
    'gray': '#5f6368',
    'light_gray': '#e8eaed',
    'bg': '#f8f9fa',
    'text': '#202124',
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
defaults = {
    'credentials': None, 'keyword_data': None, 'authenticated': False,
    'sites': [], 'analysis_results': None, 'filter_keyword': '', 'display_count': 100,
    'industry': 'åŒ»ç™‚æ©Ÿé–¢',  # æ¥­ç¨®é¸æŠ
    'oauth_tokens': None  # OAuthãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜ç”¨
}
for key, val in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = val

def apply_theme(fig, height=400):
    fig.update_layout(
        template='plotly_white',
        paper_bgcolor='white',
        plot_bgcolor='white',
        font=dict(family='Roboto, sans-serif', color=COLORS['text'], size=12),
        height=height,
        margin=dict(l=60, r=40, t=60, b=80),
        hoverlabel=dict(bgcolor='white', font_size=12, bordercolor=COLORS['light_gray']),
    )
    fig.update_xaxes(
        showgrid=True, gridcolor=COLORS['light_gray'], gridwidth=1,
        showline=True, linecolor=COLORS['light_gray'], linewidth=1,
        tickfont=dict(size=11, color=COLORS['gray']),
        title_font=dict(size=12, color=COLORS['gray'])
    )
    fig.update_yaxes(
        showgrid=True, gridcolor=COLORS['light_gray'], gridwidth=1,
        showline=True, linecolor=COLORS['light_gray'], linewidth=1,
        tickfont=dict(size=11, color=COLORS['gray']),
        title_font=dict(size=12, color=COLORS['gray'])
    )
    return fig

# èªè¨¼æ©Ÿèƒ½ï¼ˆWeb OAuthå¯¾å¿œï¼‰
def get_google_auth_url():
    """Google OAuthèªè¨¼URLã‚’ç”Ÿæˆ"""
    if not GOOGLE_CLIENT_ID:
        return None

    params = {
        'client_id': GOOGLE_CLIENT_ID,
        'redirect_uri': REDIRECT_URI,
        'scope': ' '.join(SCOPES),
        'response_type': 'code',
        'access_type': 'offline',
        'prompt': 'consent'
    }

    from urllib.parse import urlencode
    auth_url = f"https://accounts.google.com/o/oauth2/v2/auth?{urlencode(params)}"
    return auth_url

def exchange_code_for_tokens(code):
    """èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã«äº¤æ›"""
    import requests

    token_url = 'https://oauth2.googleapis.com/token'
    data = {
        'code': code,
        'client_id': GOOGLE_CLIENT_ID,
        'client_secret': GOOGLE_CLIENT_SECRET,
        'redirect_uri': REDIRECT_URI,
        'grant_type': 'authorization_code'
    }

    try:
        response = requests.post(token_url, data=data)
        if response.status_code == 200:
            tokens = response.json()
            # Credentialsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            creds = Credentials(
                token=tokens.get('access_token'),
                refresh_token=tokens.get('refresh_token'),
                token_uri='https://oauth2.googleapis.com/token',
                client_id=GOOGLE_CLIENT_ID,
                client_secret=GOOGLE_CLIENT_SECRET,
                scopes=SCOPES
            )
            return creds
    except Exception as e:
        st.error(f"ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return None

def save_credentials_json(content):
    try:
        with open(CREDENTIALS_PATH, 'w') as f:
            json.dump(json.loads(content), f)
        return True
    except:
        return False

def load_saved_credentials():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿è¾¼ã¿
    if 'oauth_tokens' in st.session_state and st.session_state.oauth_tokens:
        try:
            tokens = st.session_state.oauth_tokens
            creds = Credentials(
                token=tokens.get('access_token'),
                refresh_token=tokens.get('refresh_token'),
                token_uri='https://oauth2.googleapis.com/token',
                client_id=GOOGLE_CLIENT_ID,
                client_secret=GOOGLE_CLIENT_SECRET,
                scopes=SCOPES
            )
            if creds and creds.valid:
                return creds
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
                st.session_state.oauth_tokens = {
                    'access_token': creds.token,
                    'refresh_token': creds.refresh_token
                }
                return creds
        except:
            pass
    return None

def authenticate():
    if not os.path.exists(CREDENTIALS_PATH):
        return None
    try:
        flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_PATH, SCOPES)
        creds = flow.run_local_server(port=8080, prompt='consent')
        with open(TOKEN_PATH, 'wb') as f:
            pickle.dump(creds, f)
        return creds
    except:
        return None

def get_service(creds):
    try:
        return build('searchconsole', 'v1', credentials=creds)
    except:
        return None

def get_sites(service):
    try:
        return [s['siteUrl'] for s in service.sites().list().execute().get('siteEntry', [])]
    except:
        return []

def get_data(service, url, start, end):
    try:
        resp = service.searchanalytics().query(siteUrl=url, body={
            'startDate': start, 'endDate': end, 'dimensions': ['query'], 'rowLimit': 5000
        }).execute()
        return pd.DataFrame([{
            'query': r['keys'][0], 'clicks': r['clicks'], 'impressions': r['impressions'],
            'ctr': round(r['ctr']*100, 2), 'position': round(r['position'], 1)
        } for r in resp.get('rows', [])])
    except:
        return pd.DataFrame()

def logout():
    if os.path.exists(TOKEN_PATH):
        os.remove(TOKEN_PATH)
    for key in ['credentials', 'authenticated', 'sites', 'oauth_tokens']:
        st.session_state[key] = defaults.get(key, None)

# ===================================
# æ¥­ç¨®åˆ¥ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ä»˜ãå°‚é–€ç”¨èªè¾æ›¸
# ===================================

# å…±é€šã‚«ãƒ†ã‚´ãƒªï¼ˆå…¨æ¥­ç¨®ã§ä½¿ç”¨ï¼‰
COMMON_CATEGORIES = {
    'è©•ä¾¡ãƒ»å“è³ª': {
        'ãŠã™ã™ã‚', 'ã‚ªã‚¹ã‚¹ãƒ¡', 'äººæ°—', 'æœ‰å', 'è©•åˆ¤', 'å£ã‚³ãƒŸ', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼',
        'ä¸Šæ‰‹', 'ä¸Šæ‰‹ã„', 'ã†ã¾ã„', 'ä¿¡é ¼', 'å®‰å¿ƒ', 'ä¸å¯§', 'è¦ªåˆ‡',
        'æœ€æ–°', 'å…ˆé€²', 'æœ€å…ˆç«¯', 'é«˜åº¦', 'å°‚é–€', 'ç‰¹åŒ–', 'å®Ÿç¸¾',
        'ãƒ©ãƒ³ã‚­ãƒ³ã‚°', 'æ¯”è¼ƒ', 'ãƒ™ã‚¹ãƒˆ', 'ãƒˆãƒƒãƒ—', 'No1', 'ãƒŠãƒ³ãƒãƒ¼ãƒ¯ãƒ³',
        'è‰¯ã„', 'æ‚ªã„', 'ã„ã„', 'ãƒ€ãƒ¡', 'æœ€é«˜', 'æœ€æ‚ª', 'æº€è¶³', 'ä¸æº€',
    },
    'ä¾¡æ ¼ãƒ»è²»ç”¨': {
        'æ–™é‡‘', 'è²»ç”¨', 'ä¾¡æ ¼', 'å€¤æ®µ', 'ç›¸å ´', 'ã‚³ã‚¹ãƒˆ', 'è¦‹ç©ã‚‚ã‚Š', 'è¦‹ç©ã‚Š',
        'å®‰ã„', 'æ ¼å®‰', 'æ¿€å®‰', 'ä½ä¾¡æ ¼', 'ãƒªãƒ¼ã‚ºãƒŠãƒ–ãƒ«', 'ãŠå¾—', 'å‰²å¼•', 'ã‚»ãƒ¼ãƒ«',
        'é«˜ã„', 'é«˜é¡', 'é«˜ç´š', 'ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ',
        'ç„¡æ–™', 'ã‚¿ãƒ€', '0å††', 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³', 'ã‚¯ãƒ¼ãƒãƒ³', 'ãƒã‚¤ãƒ³ãƒˆ',
        'åˆ†å‰²', 'ãƒ­ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ', 'æœˆé¡', 'å¹´é¡', 'ã‚µãƒ–ã‚¹ã‚¯',
    },
    'æ™‚é–“ãƒ»ã‚¢ã‚¯ã‚»ã‚¹': {
        'äºˆç´„', 'å½“æ—¥', 'å³æ—¥', 'ä»Šæ—¥', 'æ˜æ—¥', 'åœŸæ›œ', 'æ—¥æ›œ', 'ç¥æ—¥',
        'å¤œé–“', 'æ·±å¤œ', 'æ—©æœ', '24æ™‚é–“', 'å¹´ä¸­ç„¡ä¼‘', 'å–¶æ¥­æ™‚é–“', 'å®šä¼‘æ—¥',
        'å¾…ã¡æ™‚é–“', 'å¾…ãŸãªã„', 'ã™ã', 'çŸ­æ™‚é–“', 'å³å¯¾å¿œ', 'ã‚¹ãƒ”ãƒ¼ãƒ‰',
        'è¿‘ã', 'è¿‘ã„', 'é§…è¿‘', 'é§…å‰', 'å¾’æ­©', 'ã‚¢ã‚¯ã‚»ã‚¹', 'é§è»Šå ´',
        'é€šã„ã‚„ã™ã„', 'è¡Œãã‚„ã™ã„', 'ä¾¿åˆ©',
    },
    'åœ°åŸŸ': {
        'æ±äº¬', 'å¤§é˜ª', 'åå¤å±‹', 'ç¦å²¡', 'æœ­å¹Œ', 'ä»™å°', 'åºƒå³¶', 'æ¨ªæµœ', 'ç¥æˆ¸', 'äº¬éƒ½',
        'åŸ¼ç‰', 'åƒè‘‰', 'ç¥å¥ˆå·', 'æ„›çŸ¥', 'å…µåº«', 'åŒ—æµ·é“', 'æ²–ç¸„',
        'æ–°å®¿', 'æ¸‹è°·', 'æ± è¢‹', 'éŠ€åº§', 'å“å·', 'ä¸Šé‡', 'ç§‹è‘‰åŸ',
        'æ¢…ç”°', 'é›£æ³¢', 'ãªã‚“ã°', 'å¿ƒæ–æ©‹', 'å¤©ç‹å¯º',
        'é§…å‰', 'é§…è¿‘', 'è¿‘ã', 'å‘¨è¾º', 'å¸‚å†…', 'çœŒå†…', 'åœ°åŸŸ', 'ã‚¨ãƒªã‚¢',
    },
}

# ===== åŒ»ç™‚æ©Ÿé–¢å‘ã‘ã‚«ãƒ†ã‚´ãƒª =====
MEDICAL_CATEGORIES = {
    'è¨ºç™‚ç§‘': {
        # å†…ç§‘ç³»
        'å†…ç§‘', 'æ¶ˆåŒ–å™¨å†…ç§‘', 'å¾ªç’°å™¨å†…ç§‘', 'å‘¼å¸å™¨å†…ç§‘', 'ç¥çµŒå†…ç§‘', 'è…è‡“å†…ç§‘',
        'å†…åˆ†æ³Œå†…ç§‘', 'ç³–å°¿ç—…å†…ç§‘', 'è¡€æ¶²å†…ç§‘', 'ãƒªã‚¦ãƒãƒç§‘', 'ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç§‘',
        'æ„ŸæŸ“ç—‡ç§‘', 'å¿ƒç™‚å†…ç§‘', 'ç·åˆå†…ç§‘', 'è€å¹´å†…ç§‘', 'è‚è‡“å†…ç§‘', 'è† åŸç—…ç§‘',
        # å¤–ç§‘ç³»
        'å¤–ç§‘', 'æ¶ˆåŒ–å™¨å¤–ç§‘', 'å¿ƒè‡“è¡€ç®¡å¤–ç§‘', 'å‘¼å¸å™¨å¤–ç§‘', 'è„³ç¥çµŒå¤–ç§‘', 'ä¹³è…ºå¤–ç§‘',
        'æ•´å½¢å¤–ç§‘', 'å½¢æˆå¤–ç§‘', 'ç¾å®¹å¤–ç§‘', 'å°å…å¤–ç§‘', 'ç§»æ¤å¤–ç§‘', 'è¡€ç®¡å¤–ç§‘',
        # å°‚é–€ç§‘
        'çœ¼ç§‘', 'è€³é¼»å’½å–‰ç§‘', 'è€³é¼»ç§‘', 'çš®è†šç§‘', 'æ³Œå°¿å™¨ç§‘', 'ç”£å©¦äººç§‘', 'ç”£ç§‘', 'å©¦äººç§‘',
        'å°å…ç§‘', 'ç²¾ç¥ç§‘', 'ãƒ¡ãƒ³ã‚¿ãƒ«ã‚¯ãƒªãƒ‹ãƒƒã‚¯', 'ç¥çµŒç§‘', 'æ”¾å°„ç·šç§‘', 'éº»é…”ç§‘',
        'ãƒšã‚¤ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯', 'ãƒªãƒãƒ“ãƒªãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç§‘', 'æ•‘æ€¥ç§‘', 'ç·©å’Œã‚±ã‚¢ç§‘', 'è…«ç˜ç§‘',
        # æ­¯ç§‘ç³»
        'æ­¯ç§‘', 'çŸ¯æ­£æ­¯ç§‘', 'å°å…æ­¯ç§‘', 'å£è…”å¤–ç§‘', 'å¯©ç¾æ­¯ç§‘', 'ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆç§‘', 'æ­¯ç§‘å£è…”å¤–ç§‘',
    },

    'æ–½è¨­': {
        'ã‚¯ãƒªãƒ‹ãƒƒã‚¯', 'ãƒ›ã‚¹ãƒ”ã‚¿ãƒ«', 'ç·åˆç—…é™¢', 'å¤§å­¦ç—…é™¢', 'å°‚é–€å¤–æ¥', 'è¨ºç™‚æ‰€',
        'åŒ»é™¢', 'ç—…é™¢', 'ã‚»ãƒ³ã‚¿ãƒ¼', 'å¥è¨ºã‚»ãƒ³ã‚¿ãƒ¼', 'ãƒ‰ãƒƒã‚¯ã‚¯ãƒªãƒ‹ãƒƒã‚¯',
        'æ¥éª¨é™¢', 'æ•´éª¨é™¢', 'é¼ç¸é™¢', 'æ²»ç™‚é™¢', 'è–¬å±€', 'ãƒ‰ãƒ©ãƒƒã‚°ã‚¹ãƒˆã‚¢',
        'ä»‹è­·æ–½è¨­', 'è€äººãƒ›ãƒ¼ãƒ ', 'ãƒ‡ã‚¤ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒªãƒãƒ“ãƒªæ–½è¨­',
    },

    'ç—…åãƒ»ç–¾æ‚£': {
        # å†…ç§‘ç³»ç–¾æ‚£
        'é«˜è¡€åœ§', 'ç³–å°¿ç—…', 'è„‚è³ªç•°å¸¸ç—‡', 'å‹•è„ˆç¡¬åŒ–', 'å¿ƒç­‹æ¢—å¡', 'è„³å’ä¸­', 'è„³æ¢—å¡',
        'ç‹­å¿ƒç—‡', 'ä¸æ•´è„ˆ', 'å¿ƒä¸å…¨', 'è‚ºç‚', 'å–˜æ¯', 'æ°—ç®¡æ”¯ç‚', 'COPD',
        'èƒƒæ½°ç˜', 'åäºŒæŒ‡è…¸æ½°ç˜', 'é€†æµæ€§é£Ÿé“ç‚', 'èƒƒç‚', 'è…¸ç‚', 'éæ•æ€§è…¸ç—‡å€™ç¾¤',
        'è‚ç‚', 'è‚ç¡¬å¤‰', 'è„‚è‚ªè‚', 'è†µç‚', 'èƒ†çŸ³', 'è…ä¸å…¨', 'è…ç‚',
        'ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¶', 'ã‚³ãƒ­ãƒŠ', 'ãƒ”ãƒ­ãƒª', 'ãƒãƒ­ã‚¦ã‚¤ãƒ«ã‚¹', 'å¸¯çŠ¶ç–±ç–¹',
        'ãƒ¡ã‚¿ãƒœãƒªãƒƒã‚¯', 'ãƒ¡ã‚¿ãƒœãƒªãƒƒã‚¯ã‚·ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ ', 'ç—›é¢¨', 'è²§è¡€', 'ç”²çŠ¶è…º',
        # ãŒã‚“
        'ãŒã‚“', 'ç™Œ', 'è…«ç˜', 'æ‚ªæ€§è…«ç˜', 'è‰¯æ€§è…«ç˜', 'ä¹³ãŒã‚“', 'èƒƒãŒã‚“', 'å¤§è…¸ãŒã‚“',
        'è‚ºãŒã‚“', 'è‚è‡“ãŒã‚“', 'è†µè‡“ãŒã‚“', 'å‰ç«‹è…ºãŒã‚“', 'å­å®®ãŒã‚“', 'åµå·£ãŒã‚“',
        # æ•´å½¢å¤–ç§‘ç³»
        'éª¨æŠ˜', 'è„±è‡¼', 'æ»æŒ«', 'ãƒ˜ãƒ«ãƒ‹ã‚¢', 'æ¤é–“æ¿ãƒ˜ãƒ«ãƒ‹ã‚¢', 'è„ŠæŸ±ç®¡ç‹­çª„ç—‡',
        'è…°ç—›', 'è‚©ã“ã‚Š', 'é–¢ç¯€ç—›', 'äº”åè‚©', 'å››åè‚©', 'è…±é˜ç‚', 'é–¢ç¯€ãƒªã‚¦ãƒãƒ',
        'å¤‰å½¢æ€§è†é–¢ç¯€ç—‡', 'å¤‰å½¢æ€§è‚¡é–¢ç¯€ç—‡', 'ãã£ãã‚Šè…°', 'åéª¨ç¥çµŒç—›', 'é ¸æ¤ç—‡',
        # çœ¼ç§‘ç³»
        'ç™½å†…éšœ', 'ç·‘å†…éšœ', 'ç¶²è†œå‰¥é›¢', 'åŠ é½¢é»„æ–‘å¤‰æ€§', 'ç³–å°¿ç—…ç¶²è†œç—‡',
        'ãƒ‰ãƒ©ã‚¤ã‚¢ã‚¤', 'çµè†œç‚', 'çœ¼ç¼ä¸‹å‚', 'æ–œè¦–', 'å¼±è¦–', 'è¿‘è¦–', 'é è¦–', 'ä¹±è¦–', 'è€çœ¼',
        'é£›èšŠç—‡', 'çœ¼ç²¾ç–²åŠ´', 'ã‚‚ã®ã‚‚ã‚‰ã„',
        # è€³é¼»ç§‘ç³»
        'ä¸­è€³ç‚', 'å¤–è€³ç‚', 'é›£è´', 'çªç™ºæ€§é›£è´', 'ãƒ¡ãƒ‹ã‚¨ãƒ¼ãƒ«ç—…', 'è€³é³´ã‚Š',
        'å‰¯é¼»è…”ç‚', 'è“„è†¿ç—‡', 'ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼æ€§é¼»ç‚', 'èŠ±ç²‰ç—‡', 'é¼»ç‚', 'æ‰æ¡ƒç‚',
        'å’½é ­ç‚', 'å–‰é ­ç‚', 'å£°å¸¯ãƒãƒªãƒ¼ãƒ—', 'ã„ã³ã', 'ç¡çœ æ™‚ç„¡å‘¼å¸ç—‡å€™ç¾¤',
        # çš®è†šç§‘ç³»
        'ã‚¢ãƒˆãƒ”ãƒ¼', 'ã‚¢ãƒˆãƒ”ãƒ¼æ€§çš®è†šç‚', 'æ¹¿ç–¹', 'è•éº»ç–¹', 'ä¹¾ç™¬', 'æ°´è™«', 'ç™½ç™¬',
        'ãƒ‹ã‚­ãƒ“', 'å¹ãå‡ºç‰©', 'ã‚·ãƒŸ', 'ã‚·ãƒ¯', 'ãŸã‚‹ã¿', 'ã»ãã‚', 'ã‚¤ãƒœ', 'ã‚ã–',
        'è„±æ¯›ç—‡', 'å††å½¢è„±æ¯›ç—‡', 'AGA', 'è–„æ¯›', 'ãƒ˜ãƒ«ãƒšã‚¹', 'å¸¯çŠ¶ç–±ç–¹',
        # æ³Œå°¿å™¨ç§‘ç³»
        'è†€èƒ±ç‚', 'å‰ç«‹è…ºè‚¥å¤§', 'å‰ç«‹è…ºç‚', 'å°¿è·¯çµçŸ³', 'è…çµçŸ³', 'å°¿å¤±ç¦', 'é »å°¿',
        'ED', 'å‹ƒèµ·ä¸å…¨', 'æ€§ç—…', 'æ€§æ„ŸæŸ“ç—‡',
        # å©¦äººç§‘ç³»
        'å­å®®ç­‹è…«', 'å­å®®å†…è†œç—‡', 'åµå·£åš¢è…«', 'æœˆçµŒå›°é›£ç—‡', 'ç”Ÿç†ä¸é †', 'æ›´å¹´æœŸéšœå®³',
        'ä¸å¦Šç—‡', 'å¦Šå¨ ', 'å‡ºç”£', 'ã¤ã‚ã‚Š', 'ä¹³è…ºç‚',
        # ç²¾ç¥ç§‘ç³»
        'ã†ã¤ç—…', 'é¬±', 'ä¸çœ ç—‡', 'ç¡çœ éšœå®³', 'ãƒ‘ãƒ‹ãƒƒã‚¯éšœå®³', 'é©å¿œéšœå®³',
        'çµ±åˆå¤±èª¿ç—‡', 'åŒæ¥µæ€§éšœå®³', 'ADHD', 'ç™ºé”éšœå®³', 'è‡ªå¾‹ç¥çµŒå¤±èª¿ç—‡', 'èªçŸ¥ç—‡',
        # æ­¯ç§‘ç³»
        'è™«æ­¯', 'æ­¯å‘¨ç—…', 'æ­¯è‚‰ç‚', 'æ­¯æ§½è†¿æ¼', 'çŸ¥è¦šéæ•', 'é¡é–¢ç¯€ç—‡', 'å£å†…ç‚',
        'è¦ªçŸ¥ã‚‰ãš', 'æ­¯ä¸¦ã³', 'ä¸æ­£å’¬åˆ', 'å‡ºã£æ­¯', 'å—ã‘å£',
        # å°å…ç§‘ç³»
        'ç™ºç†±', 'é¢¨é‚ª', 'æ‰‹è¶³å£ç—…', 'RSã‚¦ã‚¤ãƒ«ã‚¹', 'ãŠãŸãµã', 'ã¯ã—ã‹', 'æ°´ç–±ç˜¡',
    },

    'ç—‡çŠ¶': {
        'ç—›ã¿', 'ç—›ã„', 'è…«ã‚Œ', 'è…«ã‚Œã‚‹', 'ã‹ã‚†ã¿', 'ã‹ã‚†ã„', 'ã—ã³ã‚Œ', 'ã ã‚‹ã„',
        'é ­ç—›', 'è…¹ç—›', 'èƒ¸ç—›', 'èƒŒä¸­ç—›', 'é¦–ç—›', 'æ­¯ç—›', 'é–¢ç¯€ç—›', 'ç­‹è‚‰ç—›',
        'åãæ°—', 'å˜”å', 'ä¸‹ç—¢', 'ä¾¿ç§˜', 'è¡€ä¾¿', 'è¡€å°¿', 'é »å°¿', 'æ®‹å°¿æ„Ÿ',
        'å’³', 'ç—°', 'é¼»æ°´', 'é¼»ã¥ã¾ã‚Š', 'ãã—ã‚ƒã¿', 'å–‰ã®ç—›ã¿', 'å£°ãŒã‚Œ',
        'ç™ºç†±', 'å¾®ç†±', 'æ‚ªå¯’', 'å€¦æ€ æ„Ÿ', 'ç–²åŠ´', 'ã‚ã¾ã„', 'ãµã‚‰ã¤ã', 'ç«‹ã¡ãã‚‰ã¿',
        'å‹•æ‚¸', 'æ¯åˆ‡ã‚Œ', 'èƒ¸ã‚„ã‘', 'ã‚€ãã¿', 'æµ®è…«', 'å†·ãˆ', 'å†·ãˆæ€§',
        'ã‹ã™ã¿ç›®', 'å……è¡€', 'ç›®ã‚„ã«', 'æ¶™ç›®', 'çœ¼ç—›',
        'è€³é³´ã‚Š', 'è€³å‚ã‚Œ', 'è€³ç—›', 'èã“ãˆã«ãã„',
        'å‡ºè¡€', 'ã‚ã–', 'ç™ºç–¹', 'æ¹¿ç–¹', 'ã˜ã‚“ã¾ã—ã‚“', 'æ°´ã¶ãã‚Œ', 'ãŸã ã‚Œ',
        'æŠœã‘æ¯›', 'ãƒ•ã‚±', 'ã¹ãŸã¤ã', 'ä¹¾ç‡¥', 'ã²ã³å‰²ã‚Œ',
        'ä¸çœ ', 'çœ ã‚Œãªã„', 'é£Ÿæ¬²ä¸æŒ¯', 'ä½“é‡æ¸›å°‘', 'ä½“é‡å¢—åŠ ',
        'ç‰©å¿˜ã‚Œ', 'é›†ä¸­åŠ›ä½ä¸‹', 'ã‚¤ãƒ©ã‚¤ãƒ©', 'ä¸å®‰', 'æ†‚é¬±',
    },

    'ä½“ã®éƒ¨ä½': {
        'é ­', 'é¡”', 'é¡', 'ãŠã§ã“', 'ç›®', 'çœ¼', 'é¼»', 'è€³', 'å£', 'å”‡', 'èˆŒ', 'æ­¯', 'æ­¯èŒ',
        'é¡', 'ã‚ã”', 'é ¬', 'ã»ã»', 'é¦–', 'å–‰', 'ã®ã©', 'è‚©', 'è…•', 'è‚˜', 'æ‰‹é¦–', 'æ‰‹', 'æŒ‡',
        'èƒ¸', 'ä¹³æˆ¿', 'ãŠã£ã±ã„', 'èƒŒä¸­', 'è…°', 'ãŠè…¹', 'è…¹éƒ¨', 'ãŠã¸ã', 'ãŠå°»', 'è‚¡',
        'å¤ªã‚‚ã‚‚', 'è†', 'ã²ã–', 'ã™ã­', 'ãµãã‚‰ã¯ã', 'è¶³é¦–', 'è¶³', 'è¶³è£', 'ã‹ã‹ã¨', 'ã¤ã¾å…ˆ',
        'å¿ƒè‡“', 'è‚º', 'è‚è‡“', 'è…è‡“', 'èƒƒ', 'è…¸', 'å¤§è…¸', 'å°è…¸', 'è†µè‡“', 'è„¾è‡“', 'èƒ†åš¢',
        'è†€èƒ±', 'å­å®®', 'åµå·£', 'å‰ç«‹è…º', 'ç”²çŠ¶è…º', 'å‰¯è…',
        'è„³', 'ç¥çµŒ', 'è¡€ç®¡', 'å‹•è„ˆ', 'é™è„ˆ', 'ãƒªãƒ³ãƒ‘', 'éª¨', 'é–¢ç¯€', 'ç­‹è‚‰', 'è…±', 'é­å¸¯',
        'çš®è†š', 'æ¯›', 'é«ª', 'çˆª', 'ã¾ã¶ãŸ', 'ã¾ã¤ã’', 'çœ‰æ¯›',
    },

    'æ²»ç™‚ãƒ»æ–½è¡“': {
        # ä¸€èˆ¬æ²»ç™‚
        'æ²»ç™‚', 'æ‰‹è¡“', 'ã‚ªãƒš', 'å‡¦ç½®', 'æ–½è¡“', 'ã‚±ã‚¢', 'ç™‚æ³•', 'ã‚»ãƒ©ãƒ”ãƒ¼',
        'æŠ•è–¬', 'ç‚¹æ»´', 'æ³¨å°„', 'äºˆé˜²æ¥ç¨®', 'ãƒ¯ã‚¯ãƒãƒ³', 'è¼¸è¡€', 'é€æ',
        'ãƒªãƒãƒ“ãƒª', 'ãƒªãƒãƒ“ãƒªãƒ†ãƒ¼ã‚·ãƒ§ãƒ³', 'ç†å­¦ç™‚æ³•', 'ä½œæ¥­ç™‚æ³•', 'è¨€èªç™‚æ³•',
        # æ­¯ç§‘æ²»ç™‚
        'ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆ', 'ãƒ›ãƒ¯ã‚¤ãƒˆãƒ‹ãƒ³ã‚°', 'ã‚»ãƒ©ãƒŸãƒƒã‚¯', 'ãƒã‚¦ã‚¹ãƒ”ãƒ¼ã‚¹', 'ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°',
        'ãƒ–ãƒªãƒƒã‚¸', 'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°', 'ãƒ«ãƒ¼ãƒˆãƒ—ãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°', 'ãƒªãƒ†ãƒ¼ãƒŠãƒ¼', 'ã‚¢ãƒ©ã‚¤ãƒŠãƒ¼',
        'ãƒ–ãƒ©ã‚±ãƒƒãƒˆ', 'ãƒ¯ã‚¤ãƒ¤ãƒ¼', 'ã‚ªãƒ¼ãƒ«ã‚»ãƒ©ãƒŸãƒƒã‚¯', 'ã‚¸ãƒ«ã‚³ãƒ‹ã‚¢', 'ãƒ©ãƒŸãƒãƒ¼ãƒˆ',
        'ãƒ™ãƒ‹ã‚¢', 'ã‚¯ãƒ©ã‚¦ãƒ³', 'ã‚¤ãƒ³ãƒ¬ãƒ¼', 'ã‚ªãƒ³ãƒ¬ãƒ¼', 'ãƒ¡ã‚¿ãƒ«ãƒœãƒ³ãƒ‰', 'å…¥ã‚Œæ­¯',
        'ãƒ‡ãƒ³ãƒãƒ£ãƒ¼', 'ã‚¤ãƒ³ãƒ“ã‚¶ãƒ©ã‚¤ãƒ³', 'ã‚¯ãƒªã‚¢ã‚¢ãƒ©ã‚¤ãƒŠãƒ¼', 'æŠœæ­¯', 'æ ¹ç®¡æ²»ç™‚', 'ç¥çµŒæ²»ç™‚',
        # çœ¼ç§‘æ²»ç™‚
        'ãƒ¬ãƒ¼ã‚·ãƒƒã‚¯', 'ICL', 'ã‚ªãƒ«ã‚½ã‚±ãƒ©ãƒˆãƒ­ã‚¸ãƒ¼', 'ãƒ•ã‚§ã‚¤ã‚­ãƒƒã‚¯', 'çœ¼å†…ãƒ¬ãƒ³ã‚º',
        'ç™½å†…éšœæ‰‹è¡“', 'ç·‘å†…éšœæ‰‹è¡“', 'ç¡å­ä½“æ‰‹è¡“', 'ãƒ¬ãƒ¼ã‚¶ãƒ¼æ²»ç™‚',
        # ç¾å®¹æ²»ç™‚
        'ãƒœãƒˆãƒƒã‚¯ã‚¹', 'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³', 'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³é…¸', 'ãƒ—ãƒ©ã‚»ãƒ³ã‚¿', 'ãƒ”ãƒ¼ãƒªãƒ³ã‚°', 'ãƒ¬ãƒ¼ã‚¶ãƒ¼',
        'ãƒ€ãƒ¼ãƒãƒšãƒ³', 'ãƒ•ã‚©ãƒˆãƒ•ã‚§ã‚¤ã‚·ãƒ£ãƒ«', 'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'ã‚¤ã‚ªãƒ³å°å…¥',
        'ãƒªãƒ•ãƒˆã‚¢ãƒƒãƒ—', 'ã‚µãƒ¼ãƒã‚¯ãƒ¼ãƒ«', 'ãƒã‚¤ãƒ•', 'ã‚¦ãƒ«ã‚»ãƒ©', 'ã‚¹ãƒ¬ãƒƒãƒ‰ãƒªãƒ•ãƒˆ',
        'ãƒ•ã‚§ã‚¤ã‚¹ãƒªãƒ•ãƒˆ', 'è„‚è‚ªå¸å¼•', 'è±Šèƒ¸', 'ã‚·ãƒªã‚³ãƒ³', 'ãƒ—ãƒ­ãƒ†ãƒ¼ã‚¼',
        'äºŒé‡æ•´å½¢', 'åŸ‹æ²¡æ³•', 'åˆ‡é–‹æ³•', 'éš†é¼»è¡“', 'å°é¡”æ•´å½¢', 'ã‚¨ãƒ©å‰Šã‚Š',
        'ã‚±ãƒŸã‚«ãƒ«ãƒ”ãƒ¼ãƒªãƒ³ã‚°', 'ãƒˆãƒ¬ãƒãƒã‚¤ãƒ³', 'ãƒã‚¤ãƒ‰ãƒ­ã‚­ãƒãƒ³', 'è„±æ¯›', 'ãƒ¬ãƒ¼ã‚¶ãƒ¼è„±æ¯›',
        # æ•´å½¢å¤–ç§‘æ²»ç™‚
        'ãƒ–ãƒ­ãƒƒã‚¯æ³¨å°„', 'ãƒˆãƒªã‚¬ãƒ¼ãƒã‚¤ãƒ³ãƒˆ', 'AKA', 'PRP', 'äººå·¥é–¢ç¯€', 'éª¨æ¥åˆè¡“',
        'ã‚«ã‚¤ãƒ­ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ãƒƒã‚¯', 'ãƒãƒƒã‚µãƒ¼ã‚¸', 'ã‚¹ãƒˆãƒ¬ãƒƒãƒ', 'ç‰½å¼•', 'ãƒ†ãƒ¼ãƒ”ãƒ³ã‚°',
        # å†…è¦–é¡ç³»
        'å†…è¦–é¡', 'èƒƒã‚«ãƒ¡ãƒ©', 'å¤§è…¸ã‚«ãƒ¡ãƒ©', 'ã‚«ãƒ—ã‚»ãƒ«å†…è¦–é¡', 'è…¹è…”é¡', 'èƒ¸è…”é¡',
        # ãã®ä»–
        'æ¼¢æ–¹', 'é¼ç¸', 'é¼', 'ç¸', 'æŒ‡åœ§', 'æ•´ä½“', 'ã‚ªã‚¹ãƒ†ã‚ªãƒ‘ã‚·ãƒ¼',
        'æ”¾å°„ç·šæ²»ç™‚', 'åŒ–å­¦ç™‚æ³•', 'æŠ—ãŒã‚“å‰¤', 'å…ç–«ç™‚æ³•', 'ãƒ›ãƒ«ãƒ¢ãƒ³ç™‚æ³•',
    },

    'æ¤œæŸ»ãƒ»è¨ºæ–­': {
        'æ¤œæŸ»', 'è¨ºæ–­', 'è¨ºå¯Ÿ', 'å•è¨º', 'è§¦è¨º', 'è´è¨º', 'è¦–è¨º',
        'CT', 'MRI', 'ãƒ¬ãƒ³ãƒˆã‚²ãƒ³', 'Xç·š', 'ã‚¨ã‚³ãƒ¼', 'è¶…éŸ³æ³¢', 'PET',
        'è¡€æ¶²æ¤œæŸ»', 'å°¿æ¤œæŸ»', 'ä¾¿æ¤œæŸ»', 'å¿ƒé›»å›³', 'è„³æ³¢', 'ç­‹é›»å›³',
        'å†…è¦–é¡æ¤œæŸ»', 'èƒƒã‚«ãƒ¡ãƒ©æ¤œæŸ»', 'å¤§è…¸ã‚«ãƒ¡ãƒ©æ¤œæŸ»', 'ãƒãƒ³ãƒ¢ã‚°ãƒ©ãƒ•ã‚£',
        'å¥è¨º', 'æ¤œè¨º', 'äººé–“ãƒ‰ãƒƒã‚¯', 'ãƒ‰ãƒƒã‚¯', 'ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°', 'ç²¾å¯†æ¤œæŸ»',
        'ãŒã‚“æ¤œè¨º', 'ä¹³ãŒã‚“æ¤œè¨º', 'å­å®®ãŒã‚“æ¤œè¨º', 'è‚ºãŒã‚“æ¤œè¨º', 'å¤§è…¸ãŒã‚“æ¤œè¨º',
        'çœ¼åº•æ¤œæŸ»', 'è¦–åŠ›æ¤œæŸ»', 'çœ¼åœ§æ¤œæŸ»', 'è´åŠ›æ¤œæŸ»',
        'ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼æ¤œæŸ»', 'éºä¼å­æ¤œæŸ»', 'PCR', 'æŠ—ä½“æ¤œæŸ»', 'æŠ—åŸæ¤œæŸ»',
        'ã‚»ã‚«ãƒ³ãƒ‰ã‚ªãƒ”ãƒ‹ã‚ªãƒ³', 'ç´¹ä»‹çŠ¶', 'è¨ºæ–­æ›¸',
    },

    'è–¬ãƒ»åŒ»è–¬å“': {
        'è–¬', 'åŒ»è–¬å“', 'å‡¦æ–¹è–¬', 'å‡¦æ–¹ç®‹', 'å¸‚è²©è–¬', 'OTC',
        'æŠ—ç”Ÿç‰©è³ª', 'æŠ—èŒè–¬', 'è§£ç†±å‰¤', 'é®ç—›å‰¤', 'ç—›ã¿æ­¢ã‚', 'ç¡çœ è–¬', 'å®‰å®šå‰¤',
        'èƒƒè–¬', 'æ•´è…¸å‰¤', 'ä¸‹å‰¤', 'ä¾¿ç§˜è–¬', 'ä¸‹ç—¢æ­¢ã‚', 'åãæ°—æ­¢ã‚',
        'ç›®è–¬', 'ç‚¹çœ¼è–¬', 'è»Ÿè†', 'ã‚¯ãƒªãƒ¼ãƒ ', 'æ¹¿å¸ƒ', 'ãƒ‘ãƒƒãƒ—',
        'ã‚¸ã‚§ãƒãƒªãƒƒã‚¯', 'å¾Œç™ºåŒ»è–¬å“', 'å…ˆç™ºåŒ»è–¬å“', 'ã‚µãƒ—ãƒª', 'ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ',
        'ãƒ“ã‚¿ãƒŸãƒ³', 'ãƒŸãƒãƒ©ãƒ«', 'ãƒ—ãƒ­ãƒ†ã‚¤ãƒ³', 'ã‚¢ãƒŸãƒé…¸',
        'ã‚¤ãƒ³ã‚¹ãƒªãƒ³', 'ã‚¹ãƒ†ãƒ­ã‚¤ãƒ‰', 'æŠ—ãƒ’ã‚¹ã‚¿ãƒŸãƒ³', 'é™åœ§å‰¤', 'åˆ©å°¿å‰¤',
    },

    # === å½¢å®¹è©ç³»ï¼ˆã©ã‚“ãªçŠ¶æ…‹ãƒ»æ¡ä»¶ã‹ï¼‰ ===
    'è©•ä¾¡ãƒ»å“è³ª': {
        'ãŠã™ã™ã‚', 'ã‚ªã‚¹ã‚¹ãƒ¡', 'äººæ°—', 'æœ‰å', 'è©•åˆ¤', 'å£ã‚³ãƒŸ', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼',
        'ååŒ»', 'å°‚é–€åŒ»', 'èªå®šåŒ»', 'æŒ‡å°åŒ»', 'ãƒ™ãƒ†ãƒ©ãƒ³', 'å®Ÿç¸¾', 'ç—‡ä¾‹æ•°',
        'ä¸Šæ‰‹', 'ä¸Šæ‰‹ã„', 'ã†ã¾ã„', 'è…•ãŒã„ã„', 'ä¿¡é ¼', 'å®‰å¿ƒ', 'ä¸å¯§',
        'æœ€æ–°', 'å…ˆé€²', 'æœ€å…ˆç«¯', 'é«˜åº¦', 'å°‚é–€', 'ç‰¹åŒ–',
        'ãƒ©ãƒ³ã‚­ãƒ³ã‚°', 'æ¯”è¼ƒ', 'ãƒ™ã‚¹ãƒˆ', 'ãƒˆãƒƒãƒ—', 'No1', 'ãƒŠãƒ³ãƒãƒ¼ãƒ¯ãƒ³',
    },

    'ä¾¡æ ¼ãƒ»è²»ç”¨': {
        'æ–™é‡‘', 'è²»ç”¨', 'ä¾¡æ ¼', 'å€¤æ®µ', 'ç›¸å ´', 'ã‚³ã‚¹ãƒˆ',
        'å®‰ã„', 'æ ¼å®‰', 'æ¿€å®‰', 'ä½ä¾¡æ ¼', 'ãƒªãƒ¼ã‚ºãƒŠãƒ–ãƒ«', 'ãŠå¾—', 'å‰²å¼•',
        'é«˜ã„', 'é«˜é¡', 'é«˜ç´š',
        'ç„¡æ–™', 'ã‚¿ãƒ€', '0å††', 'ä¿é™ºé©ç”¨', 'ä¿é™ºè¨ºç™‚', 'è‡ªè²»', 'è‡ªç”±è¨ºç™‚',
        'åˆ†å‰²', 'ãƒ­ãƒ¼ãƒ³', 'ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ', 'åŒ»ç™‚è²»æ§é™¤', 'åŠ©æˆé‡‘', 'è£œåŠ©é‡‘',
    },

    'æ™‚é–“ãƒ»ã‚¢ã‚¯ã‚»ã‚¹': {
        'äºˆç´„', 'å½“æ—¥', 'å³æ—¥', 'ä»Šæ—¥', 'æ˜æ—¥', 'åœŸæ›œ', 'æ—¥æ›œ', 'ç¥æ—¥',
        'å¤œé–“', 'æ·±å¤œ', 'æ—©æœ', '24æ™‚é–“', 'å¹´ä¸­ç„¡ä¼‘', 'ä¼‘è¨ºæ—¥',
        'å¾…ã¡æ™‚é–“', 'å¾…ãŸãªã„', 'ã™ã', 'çŸ­æ™‚é–“', 'æ—¥å¸°ã‚Š',
        'è¿‘ã', 'è¿‘ã„', 'é§…è¿‘', 'é§…å‰', 'å¾’æ­©', 'ã‚¢ã‚¯ã‚»ã‚¹', 'é§è»Šå ´',
        'é€šã„ã‚„ã™ã„', 'è¡Œãã‚„ã™ã„',
    },

    'å¯¾è±¡ãƒ»æ¡ä»¶': {
        'åˆè¨º', 'å†è¨º', 'åˆã‚ã¦', 'åˆå›', 'ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°', 'ç›¸è«‡',
        'ç”·æ€§', 'å¥³æ€§', 'å­ä¾›', 'å­ã©ã‚‚', 'å°å…', 'èµ¤ã¡ã‚ƒã‚“', 'ä¹³å…', 'å¹¼å…',
        'é«˜é½¢è€…', 'ãŠå¹´å¯„ã‚Š', 'ã‚·ãƒ‹ã‚¢', 'å¦Šå©¦', 'å¦Šå¨ ä¸­', 'æˆä¹³ä¸­',
        'ç—›ããªã„', 'ç„¡ç—›', 'éº»é…”', 'å±€æ‰€éº»é…”', 'å…¨èº«éº»é…”', 'é®é™',
        'æ—¥å¸°ã‚Š', 'å…¥é™¢', 'é€šé™¢', 'åœ¨å®…', 'å¾€è¨º', 'è¨ªå•è¨ºç™‚',
        'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¨ºç™‚', 'é éš”è¨ºç™‚', 'ãƒªãƒ¢ãƒ¼ãƒˆ', 'ãƒ†ãƒ¬ãƒ“é›»è©±',
    },
}

# ===== ä¸€èˆ¬ä¼æ¥­å‘ã‘ã‚«ãƒ†ã‚´ãƒª =====
GENERAL_CATEGORIES = {
    'æ¥­ç¨®ãƒ»æ¥­ç•Œ': {
        'IT', 'ã‚·ã‚¹ãƒ†ãƒ ', 'ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢', 'ã‚¢ãƒ—ãƒª', 'Web', 'ã‚¦ã‚§ãƒ–', 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ',
        'è£½é€ ', 'ãƒ¡ãƒ¼ã‚«ãƒ¼', 'å·¥å ´', 'ç”Ÿç”£', 'åŠ å·¥', 'çµ„ç«‹',
        'å»ºè¨­', 'å»ºç¯‰', 'åœŸæœ¨', 'ãƒªãƒ•ã‚©ãƒ¼ãƒ ', 'ãƒªãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³', 'è¨­è¨ˆ', 'æ–½å·¥',
        'ä¸å‹•ç”£', 'è³ƒè²¸', 'å£²è²·', 'ä»²ä»‹', 'ç®¡ç†', 'ãƒãƒ³ã‚·ãƒ§ãƒ³', 'ã‚¢ãƒ‘ãƒ¼ãƒˆ', 'æˆ¸å»ºã¦',
        'å°å£²', 'è²©å£²', 'ã‚·ãƒ§ãƒƒãƒ—', 'åº—èˆ—', 'ECã‚µã‚¤ãƒˆ', 'ãƒãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ—', 'é€šè²©',
        'é£²é£Ÿ', 'ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³', 'ã‚«ãƒ•ã‚§', 'å±…é…’å±‹', 'ãƒãƒ¼', 'ãƒ•ã‚¡ã‚¹ãƒˆãƒ•ãƒ¼ãƒ‰',
        'é‡‘è', 'éŠ€è¡Œ', 'è¨¼åˆ¸', 'ä¿é™º', 'ãƒ­ãƒ¼ãƒ³', 'èè³‡', 'æŠ•è³‡',
        'æ•™è‚²', 'å­¦ç¿’', 'å¡¾', 'ã‚¹ã‚¯ãƒ¼ãƒ«', 'ç ”ä¿®', 'ã‚»ãƒŸãƒŠãƒ¼', 'è¬›åº§',
        'äººæ', 'æ´¾é£', 'ç´¹ä»‹', 'è»¢è·', 'æ±‚äºº', 'æ¡ç”¨', 'ã‚­ãƒ£ãƒªã‚¢',
        'åºƒå‘Š', 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', 'PR', 'ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³', 'ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°',
        'ã‚³ãƒ³ã‚µãƒ«', 'ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°', 'é¡§å•', 'ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼',
        'ç‰©æµ', 'é…é€', 'é‹é€', 'å€‰åº«', 'è¼¸é€', 'ãƒ‡ãƒªãƒãƒªãƒ¼',
        'æ—…è¡Œ', 'è¦³å…‰', 'ãƒ„ã‚¢ãƒ¼', 'ãƒ›ãƒ†ãƒ«', 'å®¿æ³Š', 'èˆªç©º', 'ãƒˆãƒ©ãƒ™ãƒ«',
        'ç¾å®¹', 'ã‚¨ã‚¹ãƒ†', 'ã‚µãƒ­ãƒ³', 'ãƒã‚¤ãƒ«', 'ãƒ˜ã‚¢', 'ã‚¹ãƒ‘', 'ãƒãƒƒã‚µãƒ¼ã‚¸',
        'ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹', 'ã‚¸ãƒ ', 'ã‚¹ãƒãƒ¼ãƒ„', 'ãƒ¨ã‚¬', 'ãƒ”ãƒ©ãƒ†ã‚£ã‚¹', 'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°',
        'ä»‹è­·', 'ç¦ç¥‰', 'ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢', 'ã‚·ãƒ‹ã‚¢', 'ãƒ‡ã‚¤ã‚µãƒ¼ãƒ“ã‚¹',
        'æ³•å¾‹', 'å¼è­·å£«', 'å¸æ³•æ›¸å£«', 'è¡Œæ”¿æ›¸å£«', 'ç¨ç†å£«', 'ä¼šè¨ˆå£«',
    },

    'å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹': {
        'å•†å“', 'è£½å“', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'ã‚³ãƒ¼ã‚¹', 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸', 'ã‚ªãƒ—ã‚·ãƒ§ãƒ³',
        'ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³', 'ãƒ„ãƒ¼ãƒ«', 'ã‚·ã‚¹ãƒ†ãƒ ', 'ã‚¢ãƒ—ãƒª', 'ã‚½ãƒ•ãƒˆ', 'ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ',
        'æ©Ÿèƒ½', 'ç‰¹å¾´', 'ãƒ¡ãƒªãƒƒãƒˆ', 'ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ', 'é•ã„', 'æ¯”è¼ƒ',
        'å°å…¥', 'åˆ©ç”¨', 'æ´»ç”¨', 'é‹ç”¨', 'ã‚µãƒãƒ¼ãƒˆ', 'ä¿å®ˆ', 'ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹',
        'ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º', 'ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ¡ã‚¤ãƒ‰', 'ã‚ªãƒªã‚¸ãƒŠãƒ«', 'é™å®š', 'æ–°å•†å“', 'æ–°ã‚µãƒ¼ãƒ“ã‚¹',
        'å®šç•ª', 'ãƒ­ãƒ³ã‚°ã‚»ãƒ©ãƒ¼', 'ãƒ’ãƒƒãƒˆ', 'è©±é¡Œ', 'ãƒˆãƒ¬ãƒ³ãƒ‰',
    },

    'ä¼æ¥­ãƒ»çµ„ç¹”': {
        'ä¼šç¤¾', 'ä¼æ¥­', 'æ³•äºº', 'æ ªå¼ä¼šç¤¾', 'æœ‰é™ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'LLC',
        'æœ¬ç¤¾', 'æ”¯ç¤¾', 'æ”¯åº—', 'å–¶æ¥­æ‰€', 'äº‹å‹™æ‰€', 'ã‚ªãƒ•ã‚£ã‚¹',
        'å¤§æ‰‹', 'ä¸­å°', 'ãƒ™ãƒ³ãƒãƒ£ãƒ¼', 'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'è€èˆ—', 'æ–°èˆˆ',
        'ä¸Šå ´', 'éä¸Šå ´', 'å¤–è³‡', 'å›½å†…', 'ã‚°ãƒ­ãƒ¼ãƒãƒ«', 'åœ°å…ƒ', 'åœ°åŸŸå¯†ç€',
        'ä»£è¡¨', 'ç¤¾é•·', 'CEO', 'çµŒå–¶è€…', 'å‰µæ¥­è€…', 'ãƒ•ã‚¡ã‚¦ãƒ³ãƒ€ãƒ¼',
    },

    'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': {
        'è³¼å…¥', 'è²·ã†', 'ç”³è¾¼', 'ç”³ã—è¾¼ã¿', 'å¥‘ç´„', 'ç™»éŒ²', 'åŠ å…¥', 'å…¥ä¼š',
        'å•ã„åˆã‚ã›', 'ç›¸è«‡', 'è¦‹ç©ã‚‚ã‚Š', 'è¦‹ç©ã‚Š', 'è³‡æ–™è«‹æ±‚', 'ãŠå•ã„åˆã‚ã›',
        'äºˆç´„', 'æ³¨æ–‡', 'ã‚ªãƒ¼ãƒ€ãƒ¼', 'ç™ºæ³¨', 'ä¾é ¼', 'ãŠé¡˜ã„',
        'æ¤œè¨', 'æ¯”è¼ƒ', 'é¸ã³æ–¹', 'é¸ã¶', 'æ¢ã™', 'æ¢ã—æ–¹', 'è¦‹ã¤ã‘ã‚‹',
        'ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰', 'ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«', 'ç™»éŒ²', 'ãƒ­ã‚°ã‚¤ãƒ³', 'ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—',
        'è§£ç´„', 'ã‚­ãƒ£ãƒ³ã‚»ãƒ«', 'é€€ä¼š', 'è¿”å“', 'è¿”é‡‘', 'ã‚¯ãƒ¼ãƒªãƒ³ã‚°ã‚ªãƒ•',
        'å¤‰æ›´', 'æ›´æ–°', 'åˆ‡ã‚Šæ›¿ãˆ', 'ä¹—ã‚Šæ›ãˆ', 'ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰',
    },

    'å¯¾è±¡ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ': {
        'å€‹äºº', 'æ³•äºº', 'BtoB', 'BtoC', 'ä¼æ¥­å‘ã‘', 'å€‹äººå‘ã‘',
        'åˆå¿ƒè€…', 'åˆã‚ã¦', 'å…¥é–€', 'ãƒ“ã‚®ãƒŠãƒ¼', 'æœªçµŒé¨“',
        'çµŒé¨“è€…', 'ä¸Šç´šè€…', 'ãƒ—ãƒ­', 'å°‚é–€å®¶', 'ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ',
        'ç”·æ€§', 'å¥³æ€§', 'å­¦ç”Ÿ', 'ç¤¾ä¼šäºº', 'ä¸»å©¦', 'ã‚·ãƒ‹ã‚¢', 'è‹¥è€…',
        'ä¸­å°ä¼æ¥­', 'å¤§ä¼æ¥­', 'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹', 'å€‹äººäº‹æ¥­ä¸»',
    },

    'å“è³ªãƒ»ç‰¹å¾´': {
        'é«˜å“è³ª', 'ä½å“è³ª', 'å“è³ª', 'ã‚¯ã‚ªãƒªãƒ†ã‚£', 'ä¿¡é ¼æ€§', 'å®‰å®šæ€§', 'è€ä¹…æ€§',
        'å®Ÿç¸¾', 'çµŒé¨“', 'ãƒã‚¦ãƒã‚¦', 'æŠ€è¡“', 'ã‚¹ã‚­ãƒ«', 'å°‚é–€æ€§',
        'å¯¾å¿œ', 'ä¸å¯§', 'è¿…é€Ÿ', 'ã‚¹ãƒ”ãƒ¼ãƒ‡ã‚£', 'æŸ”è»Ÿ', 'ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«',
        'å®‰å…¨', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ä¿è¨¼', 'ä¿éšœ', 'ã‚¢ãƒ•ã‚¿ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹', 'ã‚µãƒãƒ¼ãƒˆ',
        'ç°¡å˜', 'ã‚·ãƒ³ãƒ—ãƒ«', 'ä½¿ã„ã‚„ã™ã„', 'ä¾¿åˆ©', 'æ‰‹è»½', 'ãŠæ‰‹è»½',
        'åŠ¹æœ', 'åŠ¹ç‡', 'æˆæœ', 'çµæœ', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'ROI',
    },
}

# ===== æ¥­ç¨®è¨­å®š =====
INDUSTRY_CONFIGS = {
    'åŒ»ç™‚æ©Ÿé–¢': {
        'categories': {**MEDICAL_CATEGORIES, **COMMON_CATEGORIES},
        'label': 'åŒ»ç™‚æ©Ÿé–¢ï¼ˆç—…é™¢ãƒ»ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ»æ­¯ç§‘ç­‰ï¼‰',
    },
    'ä¸€èˆ¬ä¼æ¥­': {
        'categories': {**GENERAL_CATEGORIES, **COMMON_CATEGORIES},
        'label': 'ä¸€èˆ¬ä¼æ¥­ï¼ˆITãƒ»å°å£²ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ç­‰ï¼‰',
    },
}

def get_industry_terms(industry='åŒ»ç™‚æ©Ÿé–¢'):
    """æ¥­ç¨®ã«å¿œã˜ãŸç”¨èªã‚»ãƒƒãƒˆã‚’å–å¾—"""
    config = INDUSTRY_CONFIGS.get(industry, INDUSTRY_CONFIGS['åŒ»ç™‚æ©Ÿé–¢'])
    terms = set()
    for category_terms in config['categories'].values():
        terms.update(category_terms)
    return terms

def get_term_to_category(industry='åŒ»ç™‚æ©Ÿé–¢'):
    """æ¥­ç¨®ã«å¿œã˜ãŸç”¨èªâ†’ã‚«ãƒ†ã‚´ãƒªé€†å¼•ãè¾æ›¸ã‚’å–å¾—"""
    config = INDUSTRY_CONFIGS.get(industry, INDUSTRY_CONFIGS['åŒ»ç™‚æ©Ÿé–¢'])
    term_to_cat = {}
    for category, terms in config['categories'].items():
        for term in terms:
            if term not in term_to_cat:
                term_to_cat[term] = []
            term_to_cat[term].append(category)
    return term_to_cat

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
MEDICAL_TERMS = get_industry_terms('åŒ»ç™‚æ©Ÿé–¢')
TERM_TO_CATEGORY = get_term_to_category('åŒ»ç™‚æ©Ÿé–¢')

@st.cache_resource
def get_tokenizer():
    return Tokenizer()

def tokenize(query, tokenizer, industry='åŒ»ç™‚æ©Ÿé–¢'):
    """å½¢æ…‹ç´ è§£æï¼ˆå°‚é–€ç”¨èªã‚’ä¿è­·ã€é•·ã„ç”¨èªã‚’å„ªå…ˆï¼‰"""
    import re
    query_str = str(query)
    found_terms = []

    # æ¥­ç¨®ã«å¿œã˜ãŸç”¨èªã‚»ãƒƒãƒˆã‚’å–å¾—
    industry_terms = get_industry_terms(industry)

    # é•·ã„ç”¨èªã‹ã‚‰å„ªå…ˆçš„ã«ãƒãƒƒãƒï¼ˆéƒ¨åˆ†ä¸€è‡´ã‚’é˜²ãï¼‰
    sorted_terms = sorted(industry_terms, key=len, reverse=True)

    for term in sorted_terms:
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        if pattern.search(query_str):
            for match in pattern.finditer(query_str):
                found_terms.append(match.group())
            query_str = pattern.sub(' ', query_str)

    # é€šå¸¸ã®å½¢æ…‹ç´ è§£æ
    tokens = [t.surface for t in tokenizer.tokenize(query_str)
              if t.part_of_speech.split(',')[0] in ['åè©', 'å‹•è©', 'å½¢å®¹è©', 'å‰¯è©']
              and len(t.surface) > 1 and not t.surface.isdigit()]

    # å°‚é–€ç”¨èªã‚’è¿½åŠ 
    tokens.extend(found_terms)

    return tokens

def calc_score(row):
    pos_score = max(0, (20 - row['position']) / 20) * 50
    ctr_score = min(row['ctr'] / 10, 1) * 30
    click_score = min(row['clicks'] / 100, 1) * 20
    return round(pos_score + ctr_score + click_score, 1)

def classify(row, avg_ctr, med_pos):
    high_ctr = row['ctr'] >= avg_ctr
    good_pos = row['position'] <= med_pos
    if good_pos and high_ctr: return 'star'
    if not good_pos and high_ctr: return 'potential'
    if good_pos and not high_ctr: return 'improve'
    return 'stable'

def get_word_category(word, industry='åŒ»ç™‚æ©Ÿé–¢'):
    """å˜èªã®ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—"""
    term_to_cat = get_term_to_category(industry)
    return term_to_cat.get(word, ['ãã®ä»–'])

def analyze(df, tokenizer, filter_kw='', industry='åŒ»ç™‚æ©Ÿé–¢'):
    if filter_kw:
        df = df[df['query'].str.contains(filter_kw, case=False, na=False)]
    if df.empty:
        return None

    df = df.copy()
    df['score'] = df.apply(calc_score, axis=1)
    avg_ctr, med_pos = df['ctr'].mean(), df['position'].median()
    df['category'] = df.apply(lambda x: classify(x, avg_ctr, med_pos), axis=1)

    results = {
        'word_freq': Counter(), 'cooccurrence': Counter(),
        'word_position': defaultdict(lambda: {'å‰æ–¹': 0, 'å¾Œæ–¹': 0, 'å˜ä½“': 0}),
        'word_stats': defaultdict(lambda: {'ctr_sum': 0, 'pos_sum': 0, 'count': 0}),
        'word_categories': defaultdict(Counter),  # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å˜èªå‡ºç¾
        'category_freq': Counter(),  # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç·å‡ºç¾å›æ•°
        'total_imp': df['impressions'].sum(),
        'total_clicks': df['clicks'].sum(),
        'count': len(df),
        'avg_ctr': avg_ctr,
        'avg_pos': df['position'].mean(),
        'med_pos': med_pos,
        'df': df
    }

    for _, row in df.iterrows():
        tokens = tokenize(row['query'], tokenizer, industry)
        for i, t in enumerate(tokens):
            results['word_freq'][t] += row['impressions']
            results['word_stats'][t]['ctr_sum'] += row['ctr']
            results['word_stats'][t]['pos_sum'] += row['position']
            results['word_stats'][t]['count'] += 1

            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚’è¿½åŠ 
            categories = get_word_category(t, industry)
            for cat in categories:
                results['word_categories'][cat][t] += row['impressions']
                results['category_freq'][cat] += row['impressions']

            if len(tokens) == 1:
                results['word_position'][t]['å˜ä½“'] += row['impressions']
            elif i == 0:
                results['word_position'][t]['å‰æ–¹'] += row['impressions']
            elif i == len(tokens) - 1:
                results['word_position'][t]['å¾Œæ–¹'] += row['impressions']

        for pair in combinations(tokens, 2):
            results['cooccurrence'][tuple(sorted(pair))] += row['impressions']

    return results

def get_color(word, wp):
    pos = wp.get(word, {'å‰æ–¹': 0, 'å¾Œæ–¹': 0, 'å˜ä½“': 0})
    total = sum(pos.values())
    if total == 0: return COLORS['gray']
    if pos['å˜ä½“'] / total > 0.5: return COLORS['red']
    if pos['å‰æ–¹'] > pos['å¾Œæ–¹']: return COLORS['blue']
    if pos['å¾Œæ–¹'] > pos['å‰æ–¹']: return COLORS['green']
    return '#9334e6'

def create_wordcloud(wf, wp):
    """é«˜è§£åƒåº¦ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆï¼ˆå›³ã¨ç”»åƒãƒã‚¤ãƒŠãƒªã‚’è¿”ã™ï¼‰"""
    font_path = None
    try:
        import japanize_matplotlib
        font_path = os.path.join(os.path.dirname(japanize_matplotlib.__file__), 'fonts', 'ipaexg.ttf')
    except:
        pass
    if not font_path or not os.path.exists(font_path):
        for fp in ['/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc', '/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ ProN W3.otf',
                   '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf', '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc']:
            if os.path.exists(fp):
                font_path = fp
                break
    if not wf:
        return None, None
    try:
        # é«˜è§£åƒåº¦è¨­å®š
        wc = WordCloud(
            width=1600, height=640, background_color='white', font_path=font_path,
            max_words=80, color_func=lambda word, **kw: get_color(word, wp),
            prefer_horizontal=0.9, scale=2
        ).generate_from_frequencies(wf)

        # é«˜DPIã§matplotlibå›³ã‚’ä½œæˆ
        fig, ax = plt.subplots(figsize=(12, 4.8), dpi=150)
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        plt.tight_layout(pad=0)

        # PNGç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
        img_buffer = BytesIO()
        fig.savefig(img_buffer, format='png', dpi=200, bbox_inches='tight', pad_inches=0.1,
                    facecolor='white', edgecolor='none')
        img_buffer.seek(0)
        img_bytes = img_buffer.getvalue()

        return fig, img_bytes
    except:
        return None, None

def create_scatter(r, limit=100):
    df = r['df'].nlargest(limit, 'impressions').copy()
    if df.empty:
        return None

    cat_colors = {'star': COLORS['yellow'], 'potential': COLORS['green'], 'stable': COLORS['blue'], 'improve': COLORS['red']}
    cat_labels = {'star': 'ã‚¹ã‚¿ãƒ¼', 'potential': 'ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«', 'stable': 'å®‰å®š', 'improve': 'è¦æ”¹å–„'}

    fig = go.Figure()
    fig.add_hline(y=r['avg_ctr'], line_dash="dot", line_color="#dadce0", line_width=1)
    fig.add_vline(x=r['med_pos'], line_dash="dot", line_color="#dadce0", line_width=1)

    for cat in ['star', 'potential', 'stable', 'improve']:
        sub = df[df['category'] == cat]
        if not sub.empty:
            sizes = sub['impressions'].apply(lambda x: min(28, max(8, np.log(x+1)*2.8)))
            fig.add_trace(go.Scatter(
                x=sub['position'], y=sub['ctr'], mode='markers', name=cat_labels[cat],
                marker=dict(size=sizes, color=cat_colors[cat], opacity=0.8, line=dict(width=1, color='white')),
                text=sub['query'], hovertemplate="<b>%{text}</b><br>é †ä½: %{x:.1f}<br>CTR: %{y:.1f}%<extra></extra>"
            ))

    y_max = df['ctr'].max() if not df.empty else 10
    x_max = df['position'].max() if not df.empty else 100

    fig.update_layout(
        xaxis_title='æ²è¼‰é †ä½ï¼ˆå·¦ãŒä¸Šä½ï¼‰', yaxis_title='CTRï¼ˆ%ï¼‰',
        xaxis=dict(autorange='reversed', range=[x_max * 1.1, 0]),
        yaxis=dict(range=[0, y_max * 1.25]),
        legend=dict(orientation='h', y=-0.18, x=0.5, xanchor='center', font=dict(size=11), bgcolor='rgba(255,255,255,0)'),
        title=dict(text=f'<span style="font-size:11px;color:#5f6368">å¹³å‡CTR: {r["avg_ctr"]:.2f}%ã€€ï½œã€€ä¸­å¤®é †ä½: {r["med_pos"]:.1f}</span>', x=0.5, y=0.98, xanchor='center')
    )
    return apply_theme(fig, 480)

def create_word_chart(r, limit=12):
    ws, wf = r['word_stats'], r['word_freq']
    if not ws:
        return None

    data = []
    for w, f in wf.most_common(limit):
        s = ws.get(w, {})
        c = s.get('count', 1)
        data.append({'word': w, 'volume': f, 'ctr': s.get('ctr_sum', 0)/c if c else 0, 'pos': s.get('pos_sum', 0)/c if c else 0})

    df = pd.DataFrame(data)
    ctr_norm = (df['ctr'] - df['ctr'].min()) / (df['ctr'].max() - df['ctr'].min() + 0.01)
    pos_norm = (df['pos'].max() - df['pos']) / (df['pos'].max() - df['pos'].min() + 0.01)
    df['score'] = ctr_norm * 50 + pos_norm * 50

    fig = go.Figure(go.Bar(
        y=df['word'], x=df['volume'], orientation='h',
        marker=dict(color=df['score'], colorscale=[[0, COLORS['red']], [0.5, COLORS['yellow']], [1, COLORS['green']]], line=dict(width=0)),
        text=df.apply(lambda x: f"CTR {x['ctr']:.1f}%ã€€é †ä½ {x['pos']:.0f}", axis=1),
        textposition='inside', textfont=dict(size=11, color='white'),
        hovertemplate="<b>%{y}</b><br>è¡¨ç¤ºå›æ•°: %{x:,}<extra></extra>"
    ))
    fig.update_layout(yaxis=dict(categoryorder='total ascending'), xaxis_title='è¡¨ç¤ºå›æ•°', bargap=0.2)
    return apply_theme(fig, 360)

def create_network(r, n=35):
    cooc, wf = r['cooccurrence'], r['word_freq']
    if not cooc:
        return None

    pairs = sorted(cooc.items(), key=lambda x: x[1], reverse=True)[:n]
    G = nx.Graph()
    for (w1, w2), c in pairs:
        G.add_edge(w1, w2, weight=c)

    pos = nx.spring_layout(G, k=2.5, iterations=50, seed=42)
    max_w = max(d['weight'] for _, _, d in G.edges(data=True))
    max_f = max(wf.values()) if wf else 1

    edge_traces = [go.Scatter(
        x=[pos[e[0]][0], pos[e[1]][0], None], y=[pos[e[0]][1], pos[e[1]][1], None],
        mode='lines', line=dict(width=max(0.5, e[2]['weight']/max_w*2), color='rgba(95,99,104,0.25)'), hoverinfo='none'
    ) for e in G.edges(data=True)]

    node_sizes = [14 + min(16, wf.get(n, 0)/max_f*16) for n in G.nodes()]
    palette = [COLORS['blue'], COLORS['green'], COLORS['yellow'], COLORS['red']] * 10

    node_trace = go.Scatter(
        x=[pos[n][0] for n in G.nodes()], y=[pos[n][1] for n in G.nodes()],
        mode='markers+text', text=list(G.nodes()), textposition='top center',
        textfont=dict(size=10, color=COLORS['text']),
        hovertext=[f"{n}: {wf.get(n,0):,}" for n in G.nodes()], hoverinfo='text',
        marker=dict(size=node_sizes, color=palette[:len(G.nodes())], line=dict(width=2, color='white'))
    )

    fig = go.Figure(data=edge_traces + [node_trace])
    fig.update_layout(showlegend=False, xaxis=dict(visible=False), yaxis=dict(visible=False), margin=dict(l=10, r=10, t=10, b=10))
    return apply_theme(fig, 400)

def create_category_chart(r):
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å˜èªåˆ†å¸ƒã‚’è¡¨ç¤º"""
    cat_freq = r.get('category_freq', {})
    if not cat_freq:
        return None

    # ã‚«ãƒ†ã‚´ãƒªã‚’å‡ºç¾é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_cats = sorted(cat_freq.items(), key=lambda x: x[1], reverse=True)[:12]
    if not sorted_cats:
        return None

    categories = [c[0] for c in sorted_cats]
    values = [c[1] for c in sorted_cats]

    # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è‰²
    cat_colors = {
        'è¨ºç™‚ç§‘': COLORS['blue'], 'æ–½è¨­': '#4285f4', 'ç—…åãƒ»ç–¾æ‚£': COLORS['red'],
        'ç—‡çŠ¶': '#ea4335', 'ä½“ã®éƒ¨ä½': '#fbbc04', 'æ²»ç™‚ãƒ»æ–½è¡“': COLORS['green'],
        'æ¤œæŸ»ãƒ»è¨ºæ–­': '#34a853', 'è–¬ãƒ»åŒ»è–¬å“': '#9334e6', 'è©•ä¾¡ãƒ»å“è³ª': '#ff6d01',
        'ä¾¡æ ¼ãƒ»è²»ç”¨': '#46bdc6', 'æ™‚é–“ãƒ»ã‚¢ã‚¯ã‚»ã‚¹': '#7baaf7', 'å¯¾è±¡ãƒ»æ¡ä»¶': '#ee675c',
        'åœ°åŸŸ': '#fcc934', 'ãã®ä»–': COLORS['gray']
    }
    colors = [cat_colors.get(c, COLORS['gray']) for c in categories]

    fig = go.Figure(go.Bar(
        y=categories, x=values, orientation='h',
        marker=dict(color=colors, line=dict(width=0)),
        text=[f'{v:,}' for v in values],
        textposition='auto', textfont=dict(size=11),
        hovertemplate="<b>%{y}</b><br>å‡ºç¾å›æ•°: %{x:,}<extra></extra>"
    ))
    fig.update_layout(
        yaxis=dict(categoryorder='total ascending'),
        xaxis_title='å‡ºç¾å›æ•°ï¼ˆè¡¨ç¤ºå›æ•°ãƒ™ãƒ¼ã‚¹ï¼‰',
        bargap=0.25
    )
    return apply_theme(fig, 380)

def create_category_detail_table(r, category):
    """ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®å˜èªè©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    word_cats = r.get('word_categories', {})
    if category not in word_cats:
        return None

    words = word_cats[category].most_common(15)
    return pd.DataFrame([{'å˜èª': w, 'å‡ºç¾å›æ•°': f'{c:,}'} for w, c in words])

# HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆPDFä»£æ›¿ï¼‰
def generate_html_report(r):
    cat_labels = {'star': 'ã‚¹ã‚¿ãƒ¼', 'potential': 'ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«', 'stable': 'å®‰å®š', 'improve': 'è¦æ”¹å–„'}
    cat_counts = r['df']['category'].value_counts()

    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
<style>
body {{ font-family: 'Helvetica Neue', Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 2rem; color: #202124; }}
h1 {{ font-size: 1.5rem; font-weight: 400; border-bottom: 2px solid #1a73e8; padding-bottom: 0.5rem; }}
h2 {{ font-size: 1.1rem; font-weight: 500; color: #1a73e8; margin-top: 2rem; }}
.summary {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem; margin: 1rem 0; }}
.card {{ background: #f8f9fa; padding: 1rem; border-radius: 8px; text-align: center; }}
.card-value {{ font-size: 1.5rem; font-weight: 500; color: #202124; }}
.card-label {{ font-size: 0.75rem; color: #5f6368; text-transform: uppercase; }}
table {{ width: 100%; border-collapse: collapse; margin: 1rem 0; }}
th, td {{ padding: 0.5rem; text-align: left; border-bottom: 1px solid #e8eaed; }}
th {{ background: #f8f9fa; font-weight: 500; }}
.date {{ color: #5f6368; font-size: 0.85rem; }}
</style></head><body>
<h1>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
<p class="date">ä½œæˆæ—¥: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</p>

<h2>ã‚µãƒãƒªãƒ¼</h2>
<div class="summary">
<div class="card"><div class="card-value">{r['count']:,}</div><div class="card-label">ã‚¯ã‚¨ãƒªæ•°</div></div>
<div class="card"><div class="card-value">{r['total_imp']:,}</div><div class="card-label">è¡¨ç¤ºå›æ•°</div></div>
<div class="card"><div class="card-value">{r['total_clicks']:,}</div><div class="card-label">ã‚¯ãƒªãƒƒã‚¯æ•°</div></div>
<div class="card"><div class="card-value">{r['avg_ctr']:.2f}%</div><div class="card-label">å¹³å‡CTR</div></div>
<div class="card"><div class="card-value">{r['avg_pos']:.1f}</div><div class="card-label">å¹³å‡é †ä½</div></div>
</div>

<h2>ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ</h2>
<table><tr><th>ã‚«ãƒ†ã‚´ãƒª</th><th>ä»¶æ•°</th><th>å‰²åˆ</th></tr>"""

    for cat, label in cat_labels.items():
        count = cat_counts.get(cat, 0)
        pct = count / r['count'] * 100 if r['count'] > 0 else 0
        html += f"<tr><td>{label}</td><td>{count:,}</td><td>{pct:.1f}%</td></tr>"

    html += """</table><h2>å˜èªãƒ©ãƒ³ã‚­ãƒ³ã‚° Top20</h2><table><tr><th>#</th><th>å˜èª</th><th>å‡ºç¾å›æ•°</th></tr>"""
    for i, (word, freq) in enumerate(r['word_freq'].most_common(20), 1):
        html += f"<tr><td>{i}</td><td>{word}</td><td>{freq:,}</td></tr>"

    html += """</table><h2>å…±èµ·ãƒšã‚¢ Top20</h2><table><tr><th>#</th><th>å˜èªãƒšã‚¢</th><th>å…±èµ·å›æ•°</th></tr>"""
    for i, ((w1, w2), freq) in enumerate(r['cooccurrence'].most_common(20), 1):
        html += f"<tr><td>{i}</td><td>{w1} + {w2}</td><td>{freq:,}</td></tr>"

    html += """</table><h2>åŠ¹ç‡ã‚¹ã‚³ã‚¢ Top20</h2><table><tr><th>#</th><th>ã‚¯ã‚¨ãƒª</th><th>CTR</th><th>é †ä½</th><th>ã‚¹ã‚³ã‚¢</th></tr>"""
    for i, (_, row) in enumerate(r['df'].nlargest(20, 'score').iterrows(), 1):
        html += f"<tr><td>{i}</td><td>{row['query']}</td><td>{row['ctr']:.1f}%</td><td>{row['position']:.1f}</td><td>{row['score']:.1f}</td></tr>"

    html += "</table></body></html>"
    return html.encode('utf-8')

DESC = {
    'scatter': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ²è¼‰é †ä½ã¨CTRã§ãƒãƒƒãƒ”ãƒ³ã‚°ã€‚å††ã®å¤§ãã•ã¯è¡¨ç¤ºå›æ•°ã‚’è¡¨ã—ã¾ã™ã€‚<br><span style="color:#1a73e8;font-size:0.8rem;">ğŸ’¡ å„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã«ãƒã‚¦ã‚¹ã‚’é‡ã­ã‚‹ã¨ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™</span>',
    'word': 'æ¤œç´¢ã‚¯ã‚¨ãƒªã«å«ã¾ã‚Œã‚‹å˜èªã®å‡ºç¾é »åº¦ã€‚è‰²ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆç·‘=è‰¯å¥½ã€èµ¤=æ”¹å–„ä½™åœ°ï¼‰ã€‚',
    'cloud': 'å˜èªã®å‡ºç¾é »åº¦ã‚’è¦–è¦šåŒ–ã€‚è‰²ã¯å‡ºç¾ä½ç½®ï¼ˆé’=å‰æ–¹ã€ç·‘=å¾Œæ–¹ã€èµ¤=å˜ä½“ï¼‰ã€‚',
    'network': 'åŒæ™‚ã«æ¤œç´¢ã•ã‚Œã‚‹å˜èªã®é–¢ä¿‚æ€§ã€‚ç·šãŒå¤ªã„ã»ã©å…±èµ·é »åº¦ãŒé«˜ã„ã€‚<br><span style="color:#1a73e8;font-size:0.8rem;">ğŸ’¡ ãƒãƒ¼ãƒ‰ã«ãƒã‚¦ã‚¹ã‚’é‡ã­ã‚‹ã¨è¡¨ç¤ºå›æ•°ãŒç¢ºèªã§ãã¾ã™</span>',
    'cooc': 'åŒã˜ã‚¯ã‚¨ãƒªå†…ã§ä¸€ç·’ã«å‡ºç¾ã™ã‚‹å˜èªãƒšã‚¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‚',
    'score': 'é †ä½ãƒ»CTRãƒ»ã‚¯ãƒªãƒƒã‚¯æ•°ã‹ã‚‰ç®—å‡ºã—ãŸã‚¹ã‚³ã‚¢ã®é«˜ã„ã‚¯ã‚¨ãƒªã€‚',
    'category': 'æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ„å‘³ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ã€‚ä¸»èªï¼ˆè¨ºç™‚ç§‘ãƒ»æ–½è¨­ãƒ»ç—…åï¼‰ã€å½¢å®¹è©ï¼ˆè©•ä¾¡ãƒ»ä¾¡æ ¼ãƒ»æ¡ä»¶ï¼‰ãªã©ã§åˆ†é¡ã•ã‚Œã¾ã™ã€‚',
}

DEMO_DATA = """query,clicks,impressions,ctr,position
æ­¯ç§‘ ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆ è²»ç”¨,150,2500,6.0,5.2
ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆ ãŠã™ã™ã‚,120,2000,6.0,4.8
ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆ ç—›ããªã„,98,1800,5.4,6.1
è¿‘ãã®æ­¯ç§‘,85,1500,5.7,5.5
æ­¯ç§‘ ãŠã™ã™ã‚,72,1200,6.0,7.2
ãƒ›ãƒ¯ã‚¤ãƒˆãƒ‹ãƒ³ã‚° æ­¯ç§‘,68,1100,6.2,4.5
æ­¯ç§‘ ãƒ©ãƒ³ã‚­ãƒ³ã‚°,62,1050,5.9,6.8
è¦ªçŸ¥ã‚‰ãš æŠœæ­¯,58,980,5.9,5.9
çŸ¯æ­£æ­¯ç§‘ è²»ç”¨,54,920,5.9,8.1
æ­¯ç§‘ äºˆç´„,51,850,6.0,6.5
å°å…æ­¯ç§‘ ãŠã™ã™ã‚,49,820,6.0,7.8
æ­¯ç§‘ æ—¥æ›œ,47,780,6.0,5.2
å¯©ç¾æ­¯ç§‘ ã‚»ãƒ©ãƒŸãƒƒã‚¯,45,750,6.0,4.1
æ­¯ç§‘ ååŒ»,42,700,6.0,6.3
è™«æ­¯ æ²»ç™‚,40,680,5.9,7.5
æ­¯å‘¨ç—… æ²»ç™‚,38,650,5.8,8.2
æ­¯ç§‘ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°,36,620,5.8,7.1
æ­¯ç§‘ è¿‘ã,34,600,5.7,5.8
æ­¯ç§‘ å£ã‚³ãƒŸ,32,580,5.5,6.9
æ­¯ç§‘ è©•åˆ¤,30,550,5.5,7.5"""

def main():
    st.title("Keyword Mining")

    # OAuthã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆURLã«codeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
    query_params = st.query_params
    if 'code' in query_params and not st.session_state.authenticated:
        code = query_params['code']
        with st.spinner("Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«æ¥ç¶šä¸­..."):
            creds = exchange_code_for_tokens(code)
            if creds:
                st.session_state.credentials = creds
                st.session_state.authenticated = True
                st.session_state.oauth_tokens = {
                    'access_token': creds.token,
                    'refresh_token': creds.refresh_token
                }
                # URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                st.query_params.clear()
                st.rerun()
            else:
                st.error("èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                st.query_params.clear()

    if not st.session_state.authenticated:
        creds = load_saved_credentials()
        if creds:
            st.session_state.credentials = creds
            st.session_state.authenticated = True

    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼šuserlocalé¢¨ã®å…¥åŠ›ç”»é¢
    if st.session_state.keyword_data is None:
        st.markdown("""
        <div style="text-align: center; padding: 1rem 0 2rem 0;">
            <p style="color: #5f6368; font-size: 0.95rem;">Search Consoleã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆã—ã¾ã™</p>
        </div>
        """, unsafe_allow_html=True)

        tab1, tab2 = st.tabs(["CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "Search Consoleé€£æº"])

        with tab1:
            st.markdown("""
            <div style="border: 2px dashed #dadce0; border-radius: 12px; padding: 2.5rem; text-align: center; background: #fafafa; margin: 1rem 0;">
                <p style="font-size: 1.1rem; color: #202124; margin-bottom: 0.5rem;">CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—</p>
                <p style="font-size: 0.85rem; color: #5f6368;">ã¾ãŸã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ</p>
            </div>
            """, unsafe_allow_html=True)

            file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=['csv'], label_visibility="collapsed")

            if file:
                try:
                    df = pd.read_csv(file)
                    st.session_state.keyword_data = df
                    st.session_state.analysis_results = None
                    st.rerun()
                except Exception as e:
                    st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

            st.markdown("---")
            st.markdown("**CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**")
            st.code("query,clicks,impressions,ctr,position", language=None)

            col1, col2 = st.columns(2)
            sample = "query,clicks,impressions,ctr,position\næ­¯ç§‘ ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆ,150,2500,6.0,5.2\nãƒ›ãƒ¯ã‚¤ãƒˆãƒ‹ãƒ³ã‚° è²»ç”¨,120,2000,6.0,4.8"
            col1.download_button("ã‚µãƒ³ãƒ—ãƒ«CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", sample, "sample.csv", use_container_width=True)
            if col2.button("ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™", type="primary", use_container_width=True):
                st.session_state.keyword_data = pd.read_csv(StringIO(DEMO_DATA))
                st.session_state.analysis_results = None
                st.rerun()

        with tab2:
            if st.session_state.authenticated:
                st.success("Google ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ¥ç¶šæ¸ˆã¿")
                if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
                    logout()
                    st.rerun()

                service = get_service(st.session_state.credentials)
                if service:
                    if not st.session_state.sites:
                        st.session_state.sites = get_sites(service)

                    if st.session_state.sites:
                        site = st.selectbox("ã‚µã‚¤ãƒˆã‚’é¸æŠ", st.session_state.sites)
                        c1, c2 = st.columns(2)
                        start = c1.date_input("é–‹å§‹æ—¥", datetime.now().date() - timedelta(days=28))
                        end = c2.date_input("çµ‚äº†æ—¥", datetime.now().date() - timedelta(days=3))

                        if st.button("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—", type="primary", use_container_width=True):
                            with st.spinner("å–å¾—ä¸­..."):
                                df = get_data(service, site, start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'))
                                if not df.empty:
                                    st.session_state.keyword_data = df
                                    st.session_state.analysis_results = None
                                    st.rerun()
                                else:
                                    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                # Googleã§ãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³
                if GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET:
                    st.markdown("""
                    <div style="text-align: center; padding: 2rem 0;">
                        <p style="color: #5f6368; margin-bottom: 1.5rem;">Search Consoleã®ãƒ‡ãƒ¼ã‚¿ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ã€Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„</p>
                    </div>
                    """, unsafe_allow_html=True)

                    auth_url = get_google_auth_url()
                    if auth_url:
                        # Googleãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³ï¼ˆãƒªãƒ³ã‚¯ã¨ã—ã¦è¡¨ç¤ºï¼‰
                        st.markdown(f"""
                        <div style="text-align: center;">
                            <a href="{auth_url}" target="_self" style="
                                display: inline-flex;
                                align-items: center;
                                gap: 12px;
                                background: white;
                                border: 1px solid #dadce0;
                                border-radius: 4px;
                                padding: 12px 24px;
                                text-decoration: none;
                                color: #3c4043;
                                font-family: 'Roboto', sans-serif;
                                font-weight: 500;
                                font-size: 14px;
                                transition: background 0.2s, box-shadow 0.2s;
                            " onmouseover="this.style.background='#f8f9fa'; this.style.boxShadow='0 1px 3px rgba(0,0,0,0.1)';"
                               onmouseout="this.style.background='white'; this.style.boxShadow='none';">
                                <svg width="18" height="18" viewBox="0 0 24 24">
                                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                                </svg>
                                Googleã§ãƒ­ã‚°ã‚¤ãƒ³
                            </a>
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.warning("OAuthè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° GOOGLE_CLIENT_ID ã¨ GOOGLE_CLIENT_SECRET ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼šåˆ†æçµæœè¡¨ç¤º
    else:
        df = st.session_state.keyword_data

        # æ¥­ç¨®é¸æŠï¼ˆä¸Šéƒ¨ã«é…ç½®ï¼‰
        industry_col1, industry_col2 = st.columns([1, 3])
        with industry_col1:
            industry_options = list(INDUSTRY_CONFIGS.keys())
            current_idx = industry_options.index(st.session_state.industry) if st.session_state.industry in industry_options else 0
            selected_industry = st.selectbox(
                "æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒª",
                industry_options,
                index=current_idx,
                format_func=lambda x: INDUSTRY_CONFIGS[x]['label'],
                key="industry_select"
            )
            if selected_industry != st.session_state.industry:
                st.session_state.industry = selected_industry
                st.session_state.analysis_results = None
                st.rerun()

        # ä¸Šéƒ¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
        filter_kw = col1.text_input("çµã‚Šè¾¼ã¿", value=st.session_state.filter_keyword, placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", label_visibility="collapsed")
        if col2.button("é©ç”¨", use_container_width=True):
            st.session_state.filter_keyword = filter_kw
            st.session_state.analysis_results = None
        if col3.button("ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.filter_keyword = ''
            st.session_state.analysis_results = None
            st.rerun()
        if col4.button("æ–°è¦ãƒ‡ãƒ¼ã‚¿", use_container_width=True):
            st.session_state.keyword_data = None
            st.session_state.analysis_results = None
            st.rerun()

        tokenizer = get_tokenizer()
        if st.session_state.analysis_results is None:
            with st.spinner("åˆ†æä¸­..."):
                st.session_state.analysis_results = analyze(df, tokenizer, st.session_state.filter_keyword, st.session_state.industry)

        r = st.session_state.analysis_results
        if r is None:
            st.warning("è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—")
            return

        # KPI
        st.divider()
        cols = st.columns(5)
        metrics = [
            ("ã‚¯ã‚¨ãƒªæ•°", f"{r['count']:,}", "åˆ†æå¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°"),
            ("è¡¨ç¤ºå›æ•°", f"{r['total_imp']:,}", "æ¤œç´¢çµæœã§ã®ç·è¡¨ç¤ºå›æ•°"),
            ("ã‚¯ãƒªãƒƒã‚¯æ•°", f"{r['total_clicks']:,}", "ç·ã‚¯ãƒªãƒƒã‚¯æ•°"),
            ("å¹³å‡CTR", f"{r['avg_ctr']:.2f}%", "ã‚¯ãƒªãƒƒã‚¯ç‡ã®å¹³å‡"),
            ("å¹³å‡é †ä½", f"{r['avg_pos']:.1f}", "æ²è¼‰é †ä½ã®å¹³å‡"),
        ]
        for col, (label, value, tip) in zip(cols, metrics):
            col.metric(label, value, help=tip)

        st.divider()

        # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆæœ€åˆã«è¡¨ç¤ºï¼‰
        st.subheader("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
        st.markdown(f'<p class="desc-text">{DESC["cloud"]}</p>', unsafe_allow_html=True)
        wc_fig, wc_img_bytes = create_wordcloud(dict(r['word_freq']), r['word_position'])
        if wc_fig:
            st.pyplot(wc_fig)
            if wc_img_bytes:
                st.download_button(
                    "ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    wc_img_bytes,
                    f"wordcloud_{datetime.now().strftime('%Y%m%d_%H%M')}.png",
                    mime="image/png",
                    use_container_width=False
                )

        st.divider()

        # CTR Ã— æ²è¼‰é †ä½
        st.subheader("CTR Ã— æ²è¼‰é †ä½")
        st.markdown(f'<p class="desc-text">{DESC["scatter"]}</p>', unsafe_allow_html=True)
        display_options = [50, 100, 200, 500]
        idx = display_options.index(st.session_state.display_count) if st.session_state.display_count in display_options else 1
        display_count = st.selectbox("è¡¨ç¤ºä»¶æ•°", display_options, index=idx, key="scatter_limit")
        st.session_state.display_count = display_count
        fig = create_scatter(r, limit=display_count)
        if fig:
            st.plotly_chart(fig, use_container_width=True)

        st.divider()

        # å˜èªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        st.subheader("å˜èªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        st.markdown(f'<p class="desc-text">{DESC["word"]}</p>', unsafe_allow_html=True)
        fig = create_word_chart(r)
        if fig:
            st.plotly_chart(fig, use_container_width=True)

        st.divider()

        # ã‚«ãƒ†ã‚´ãƒªåˆ†æï¼ˆæ–°è¦è¿½åŠ ï¼‰
        st.subheader("å˜èªã‚«ãƒ†ã‚´ãƒªåˆ†æ")
        st.markdown('<p class="desc-text">æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å«ã¾ã‚Œã‚‹å˜èªã‚’æ„å‘³ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢æ„å›³ã‚’æŠŠæ¡ã§ãã¾ã™ã€‚</p>', unsafe_allow_html=True)

        cat_col1, cat_col2 = st.columns([3, 2])

        with cat_col1:
            cat_fig = create_category_chart(r)
            if cat_fig:
                st.plotly_chart(cat_fig, use_container_width=True)

        with cat_col2:
            # ã‚«ãƒ†ã‚´ãƒªé¸æŠã§è©³ç´°è¡¨ç¤º
            cat_freq = r.get('category_freq', {})
            if cat_freq:
                sorted_cats = sorted(cat_freq.keys(), key=lambda x: cat_freq[x], reverse=True)
                selected_cat = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦è©³ç´°ã‚’è¡¨ç¤º", sorted_cats, key="cat_select")
                if selected_cat:
                    cat_detail = create_category_detail_table(r, selected_cat)
                    if cat_detail is not None and not cat_detail.empty:
                        st.dataframe(cat_detail, use_container_width=True, hide_index=True)

        st.divider()

        # å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        st.subheader("å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
        st.markdown(f'<p class="desc-text">{DESC["network"]}</p>', unsafe_allow_html=True)
        fig = create_network(r)
        if fig:
            st.plotly_chart(fig, use_container_width=True)

        st.divider()

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("å…±èµ·ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            st.markdown(f'<p class="desc-text">{DESC["cooc"]}</p>', unsafe_allow_html=True)
            cooc_df = pd.DataFrame([{'å˜èªãƒšã‚¢': f"{w1} + {w2}", 'å›æ•°': f"{c:,}"} for (w1, w2), c in r['cooccurrence'].most_common(10)])
            if not cooc_df.empty:
                st.dataframe(cooc_df, use_container_width=True, hide_index=True)

        with col2:
            st.subheader("åŠ¹ç‡ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            st.markdown(f'<p class="desc-text">{DESC["score"]}</p>', unsafe_allow_html=True)
            score_df = r['df'].nlargest(10, 'score')[['query', 'ctr', 'position', 'score']].copy()
            score_df.columns = ['ã‚¯ã‚¨ãƒª', 'CTR', 'é †ä½', 'ã‚¹ã‚³ã‚¢']
            score_df['CTR'] = score_df['CTR'].apply(lambda x: f"{x:.1f}%")
            score_df['é †ä½'] = score_df['é †ä½'].apply(lambda x: f"{x:.1f}")
            st.dataframe(score_df, use_container_width=True, hide_index=True)

        st.divider()

        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        st.subheader("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        cols = st.columns(4)
        cols[0].download_button("HTMLãƒ¬ãƒãƒ¼ãƒˆ", generate_html_report(r), f"report_{datetime.now().strftime('%Y%m%d')}.html", mime="text/html", use_container_width=True)
        cols[1].download_button("å…¨ãƒ‡ãƒ¼ã‚¿ CSV", r['df'].to_csv(index=False).encode('utf-8-sig'), "keyword_data.csv", use_container_width=True)
        word_data = [{'å˜èª': w, 'å‡ºç¾': f} for w, f in r['word_freq'].most_common()]
        cols[2].download_button("å˜èª CSV", pd.DataFrame(word_data).to_csv(index=False).encode('utf-8-sig'), "word_data.csv", use_container_width=True)
        cooc_data = [{'å˜èª1': w1, 'å˜èª2': w2, 'å…±èµ·': c} for (w1, w2), c in r['cooccurrence'].most_common()]
        cols[3].download_button("å…±èµ· CSV", pd.DataFrame(cooc_data).to_csv(index=False).encode('utf-8-sig'), "cooccurrence_data.csv", use_container_width=True)

if __name__ == "__main__":
    main()
